{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariable Linear Regression with pytorch using torch.nn\n",
    "This code is all about Multivariable linear regression which is formed like a linear euqation graph using torch.nn library.\n",
    "\n",
    "I focused on the structure of this code and try to memorize this sample code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see same results at every time, use torch.manual_seed(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x16b2c3ccaf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 80],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 79]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.size())\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we used...\n",
    "\n",
    "`W = torch.zeros((3,1), requires_grad = True)`\n",
    "\n",
    "`b = torch.zeros(1,requires_grad = True)`\n",
    "\n",
    "In this time, we will use torch.nn.Linear to make parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(x_train.shape[1], y_train.shape[1])\n",
    "print(x_train.shape[1])\n",
    "print(y_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "previous code: `optimizer = optim.SGD([W,b],lr = 1e-5)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.2975, -0.2548, -0.1119]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2710], requires_grad=True)]\n",
      "Parameter containing:\n",
      "tensor([[ 0.2975, -0.2548, -0.1119]], requires_grad=True)\n",
      "tensor([[ 0.2975, -0.2548, -0.1119]])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(),lr = 1e-5)\n",
    "print(list(model.parameters()))\n",
    "print(list(model.parameters())[0])\n",
    "print(list(model.parameters())[0].detach())\n",
    "print(type(list(model.parameters())[0].detach()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 W:tensor([[0.9214, 0.3689, 0.5142]]) b:tensor([0.2782]) Cost: 1006.170715\n",
      "Epoch    1/20 W:tensor([[0.9517, 0.3993, 0.5443]]) b:tensor([0.2786]) Cost: 325.436646\n",
      "Epoch    2/20 W:tensor([[0.9688, 0.4165, 0.5611]]) b:tensor([0.2788]) Cost: 110.561928\n",
      "Epoch    3/20 W:tensor([[0.9783, 0.4263, 0.5704]]) b:tensor([0.2789]) Cost: 42.729458\n",
      "Epoch    4/20 W:tensor([[0.9837, 0.4319, 0.5755]]) b:tensor([0.2790]) Cost: 21.309166\n",
      "Epoch    5/20 W:tensor([[0.9868, 0.4352, 0.5783]]) b:tensor([0.2790]) Cost: 14.538325\n",
      "Epoch    6/20 W:tensor([[0.9885, 0.4371, 0.5797]]) b:tensor([0.2790]) Cost: 12.391404\n",
      "Epoch    7/20 W:tensor([[0.9895, 0.4383, 0.5804]]) b:tensor([0.2790]) Cost: 11.703969\n",
      "Epoch    8/20 W:tensor([[0.9901, 0.4391, 0.5806]]) b:tensor([0.2790]) Cost: 11.477208\n",
      "Epoch    9/20 W:tensor([[0.9904, 0.4396, 0.5806]]) b:tensor([0.2790]) Cost: 11.395860\n",
      "Epoch   10/20 W:tensor([[0.9906, 0.4401, 0.5805]]) b:tensor([0.2790]) Cost: 11.360420\n",
      "Epoch   11/20 W:tensor([[0.9908, 0.4404, 0.5803]]) b:tensor([0.2790]) Cost: 11.339487\n",
      "Epoch   12/20 W:tensor([[0.9908, 0.4407, 0.5801]]) b:tensor([0.2790]) Cost: 11.323221\n",
      "Epoch   13/20 W:tensor([[0.9909, 0.4410, 0.5799]]) b:tensor([0.2790]) Cost: 11.308279\n",
      "Epoch   14/20 W:tensor([[0.9910, 0.4412, 0.5796]]) b:tensor([0.2790]) Cost: 11.293927\n",
      "Epoch   15/20 W:tensor([[0.9910, 0.4415, 0.5793]]) b:tensor([0.2790]) Cost: 11.279657\n",
      "Epoch   16/20 W:tensor([[0.9911, 0.4418, 0.5791]]) b:tensor([0.2790]) Cost: 11.265538\n",
      "Epoch   17/20 W:tensor([[0.9911, 0.4420, 0.5788]]) b:tensor([0.2790]) Cost: 11.251391\n",
      "Epoch   18/20 W:tensor([[0.9911, 0.4423, 0.5785]]) b:tensor([0.2790]) Cost: 11.237252\n",
      "Epoch   19/20 W:tensor([[0.9912, 0.4425, 0.5782]]) b:tensor([0.2790]) Cost: 11.223197\n",
      "Epoch   20/20 W:tensor([[0.9912, 0.4427, 0.5779]]) b:tensor([0.2790]) Cost: 11.209125\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(nb_epochs+1):\n",
    "    #hypothesis = x_train.matmul(W) + b\n",
    "    hypothesis = model(x_train)\n",
    "    \n",
    "    #cost = torch.mean((hypothesis - y_train)**2)\n",
    "    cost = F.mse_loss(hypothesis, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch {:4d}/{} W:{} b:{} Cost: {:3.6f}'.format(epoch, nb_epochs, list(model.parameters())[0].detach(), list(model.parameters())[1].detach(), cost.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
