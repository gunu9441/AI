{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_linear_regression_numpy","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMVx/095/DjLKgIaBP4Xr0/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1RQZzRUtgLOi"},"source":["# Linear Regression with numpy, pandas, matplotlib\n","This code is all about linear regression which is formed like an linear euqation graph.\n","\n","This code is composed of three python libraries to analyze the data structure and use linear regression."]},{"cell_type":"markdown","metadata":{"id":"N9ngrui03qbX"},"source":["### Import header file"]},{"cell_type":"code","metadata":{"id":"wFQF4xkz20cS"},"source":["from google.colab import drive\n","import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vCYSUuce3yEW"},"source":["### Mount data which exited in Google dive to colab"]},{"cell_type":"code","metadata":{"id":"LXPmJKsw3ntO"},"source":["drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LUCnM9tU4KWe"},"source":["filename = '/content/drive/MyDrive/AI/1.Linear_Regression/ex1data1.txt'\n","df = pd.read_csv(filename, header = None)\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sykbsXoP4jZI"},"source":["### Function to be used"]},{"cell_type":"markdown","metadata":{"id":"EFlL9QJqLwuD"},"source":["Establish hypothesis (y= ax+b)"]},{"cell_type":"code","metadata":{"id":"PK3GAK-x4lh_"},"source":["def hypothesis(theta, X):\n","    return theta[0] + theta[1]*X"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t94KXo-hLtrZ"},"source":["Calculate loss"]},{"cell_type":"code","metadata":{"id":"RXMS4QqR4ufD"},"source":["def cost_calc(m,theta, X, y):\n","    return 1/(2*m) * np.sum((hypothesis(theta, X) - y)**2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7mqmg1uZMFZo"},"source":["Use gradient descent to minimize the loss between inference and Y"]},{"cell_type":"code","metadata":{"id":"ZK59PSuX5R0G"},"source":["m = len(df)\n","def gradient_descent(theta, X, y, epoch, alpha, m):\n","    cost = []\n","    i = 0\n","    while i < epoch:\n","        hypo = hypothesis(theta, X)\n","        theta[0] -= alpha*(sum(hypo-y)/m)\n","        theta[1] -=(alpha * np.sum((hypo-y)*X))/m \n","        cost.append(cost_calc(m, theta, X, y))\n","        i += 1\n","    return theta, cost"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AnbZPfdRMlCK"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"_er2hq5FDTSt"},"source":["In an upper code, it update parameters(weight, bias) by using gradient descent.\n","\n","Gradient descent is a way to minimize the loss(MSE) through partial derivative with regard to weight, bias, respectively.\n","\n","It is important to memorize that dataframe can support element-wise product.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"s8ioewZpMVpn"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"q4q484GyMa0_"},"source":["Total forwarding function"]},{"cell_type":"code","metadata":{"id":"uV5EfcuK63fo"},"source":["def predict(theta, X, y, epoch, alpha):\n","    theta, cost = gradient_descent(theta, X, y, epoch, alpha, m)\n","    return hypothesis(theta, X), cost, theta"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1L38FHpn7NQB"},"source":["print(df[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U5atzZUiN3fu"},"source":["In Main..."]},{"cell_type":"code","metadata":{"id":"A8SDXsUq7FEf"},"source":["theta = [0,0]\n","y_predict, cost, theta = predict(theta, df[0], df[1], 2000, 0.01)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BPXsSwfOOHij"},"source":["### Result"]},{"cell_type":"markdown","metadata":{"id":"K1oqHm_YN_Or"},"source":["A result of parameters(weight and bias)"]},{"cell_type":"code","metadata":{"id":"tcyLa00lFqhU"},"source":["theta"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tn_nQUaKHDl3"},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","plt.figure()\n","plt.scatter(df[0], df[1], label = 'Original y')\n","plt.scatter(df[0], y_predict, label = 'predicted y')\n","plt.legend(loc = \"upper left\")\n","plt.xlabel(\"input feature\")\n","plt.ylabel(\"Original and Predicted Output\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oQEx-v7bHVMq"},"source":["plt.figure()\n","plt.scatter(range(0, len(cost)), cost)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9eXp1_--P73C"},"source":["print(type(df[0]))\n","print(type(df))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VjlGxKf1d4Iw"},"source":["### Practice pandas series and dataframe."]},{"cell_type":"code","metadata":{"id":"vk-sCh-VQAt9"},"source":["data = [1,2,3,4,5]\n","data = pd.Series(data, index = [0,1,2,3,4])\n","print(data)\n","print(type(data))\n","print(3*data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mG6x6l1Dd-Dv"},"source":["data1 = pd.DataFrame([[3,4],[2,2]], index = [0,100], columns=[10,1000])\n","print(data1)\n","print(type(data1))\n","print(data1*3)"],"execution_count":null,"outputs":[]}]}